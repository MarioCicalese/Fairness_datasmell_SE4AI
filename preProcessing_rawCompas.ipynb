{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} Recall: {recall}\")\n",
    "    print(f\"{model_name} F1 Score: {f1_score_value}\")\n",
    "\n",
    "def compute_classification_metric(dataset,predictions, label_name_v, favorable_label_v, unfavorable_label_v, privileged_attribute, unprivileged_attribute):\n",
    "    features = [privileged_attribute] + unprivileged_attribute # We want to check the fairness level regarding the protected attribute \"sex\"\n",
    "\n",
    "    # This is the object made of the original dataset\n",
    "    aif_sex_dataset = BinaryLabelDataset( # Base class for all structured datasets with binary labels.\n",
    "            df=dataset,\n",
    "            favorable_label=favorable_label_v, # This means that a prediction is biased toward the privileged attribute if its value is 1 (True)\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute], # here we tell AIF that we want to check for predictions\n",
    "        )\n",
    "\n",
    "    # We do the same thing but with the predictions dataset\n",
    "    aif_sex_pred = BinaryLabelDataset(\n",
    "            df=predictions,\n",
    "            favorable_label=favorable_label_v,\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute],\n",
    "        )\n",
    "\n",
    "    sex_privileged_group = [{privileged_attribute: 1, **{attr: 0 for attr in unprivileged_attribute}}]\n",
    "    sex_unprivileged_group = [{attr: 1, privileged_attribute: 0} for attr in unprivileged_attribute]\n",
    "\n",
    "    # We provide the ClassificationMetric object with all the information needed:\n",
    "    # aif_sex_dataset - The original test set\n",
    "    # aif_sex_pred - A dataset containing the predictions of the model\n",
    "    # sex_privileged_group - The privileged group\n",
    "    # sex_unprivileged_group - The unprivileged group\n",
    "    fairness_metrics = ClassificationMetric(dataset=aif_sex_dataset,\n",
    "                            classified_dataset=aif_sex_pred,\n",
    "                            unprivileged_groups=sex_unprivileged_group,\n",
    "                            privileged_groups=sex_privileged_group)\n",
    "    \n",
    "    return fairness_metrics\n",
    "\n",
    "def compute_fairness_metrics(fairness_metrics: ClassificationMetric):\n",
    "    # Values less than 0 indicate that privileged group has higher\n",
    "    # proportion of predicted positive outcomes than unprivileged group.\n",
    "    # Value higher than 0 indicates that unprivileged group has higher proportion\n",
    "    # of predicted positive outcomes than privileged group.\n",
    "    SPD = round(fairness_metrics.statistical_parity_difference(),3)\n",
    "\n",
    "    # Measures the deviation from the equality of opportunity, which means that the same\n",
    "    # proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
    "    EOD = round(fairness_metrics.equal_opportunity_difference(),3)\n",
    "\n",
    "    # Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
    "    # A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
    "    # groups have the same probability of being classified positively.\n",
    "    AOD = round(fairness_metrics.average_odds_difference(),3)\n",
    "\n",
    "    print(f\"Statistical Parity Difference (SPD): {SPD}\")\n",
    "    print(f\"Average Odds Difference (AOD): {AOD}\")\n",
    "    print(f\"Equal Opportunity Difference (EOD): {EOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"datasets/trained_compas-score.csv\"\n",
    "df_raw = pd.read_csv(dataset_path) \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_raw.drop(columns=\"is_recid\")\n",
    "y = df_raw[\"is_recid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sex_features = ['sex_Male','sex_Female']\n",
    "\n",
    "sex_privileged_group = [{'sex_Male': 0, 'sex_Female': 1}] # The privileged group is made of males (sex_Male = True)\n",
    "sex_unprivileged_group = [{'sex_Female': 0, 'sex_Male': 1}] # The unprivileged group is made of females (sex_Female = True)\n",
    "\n",
    "dataset = X.copy(deep=True) # we recreate a copy of the whole dataset processed and balanced\n",
    "dataset['is_recid'] = y # and join the target feature with the others\n",
    "\n",
    "# Create a BinaryLabelDataset using AIF360 library\n",
    "aif_dataset = BinaryLabelDataset(\n",
    "        df=dataset,\n",
    "        favorable_label=0,\n",
    "        unfavorable_label=1,\n",
    "        label_names=['is_recid'],\n",
    "        protected_attribute_names=sex_features,\n",
    "    )\n",
    "\n",
    "# Apply the Reweighing technique\n",
    "RW = Reweighing(unprivileged_groups=sex_unprivileged_group, privileged_groups=sex_privileged_group)\n",
    "dataset_transformed = RW.fit_transform(aif_dataset)\n",
    "\n",
    "# Get sample weights from the transformed dataset\n",
    "sample_weights = dataset_transformed.instance_weights\n",
    "\n",
    "# Create a fair dataset using the reweighing technique\n",
    "fair_dataset = dataset.copy(deep=True)\n",
    "fair_dataset['weights'] = sample_weights\n",
    "\n",
    "# Get features and target from the dataset\n",
    "features = dataset.columns.tolist()\n",
    "features.remove('is_recid')\n",
    "target = ['is_recid']\n",
    "\n",
    "# Set dataset features and target\n",
    "X_fair = fair_dataset[features]\n",
    "y_fair = fair_dataset[target]\n",
    "\n",
    "X_fair_train, X_fair_test, y_fair_train, y_fair_test, sample_weights_train, sample_weights_test = train_test_split(X_fair, y_fair, sample_weights, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.659706546275395\n",
      "Decision Tree Recall: 0.46677471636953\n",
      "Decision Tree F1 Score: 0.48854961832061067\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# The fit function will do the trick\n",
    "dt_clf.fit(X_fair_train, y_fair_train, sample_weight=sample_weights_train)\n",
    "\n",
    "# After the training phase, the model will be tested by predicting the values on the test set\n",
    "dt_predictions = dt_clf.predict(X_fair_test)\n",
    "\n",
    "compute_performance_metrics(y_fair_test,dt_predictions,\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mario\\.conda\\envs\\se4faiEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6992099322799097\n",
      "SVM Recall: 0.2884927066450567\n",
      "SVM F1 Score: 0.40044994375703036\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "# Addestra il classificatore sui dati di training\n",
    "svm_classifier.fit(X_fair_train, y_fair_train, svc__sample_weight=sample_weights_train)\n",
    "\n",
    "# Fai delle predizioni sui dati di test\n",
    "svm_pred = svm_classifier.predict(X_fair_test)\n",
    "\n",
    "compute_performance_metrics(y_fair_test,svm_pred,\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mario\\.conda\\envs\\se4faiEnv\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7065462753950339\n",
      "Random Forest Recall: 0.4051863857374392\n",
      "Random Forest F1 Score: 0.49019607843137253\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth = None, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_fair_train, y_fair_train, sample_weight=sample_weights_train)\n",
    "\n",
    "rf_predictions = rf_classifier.predict(X_fair_test)\n",
    "\n",
    "compute_performance_metrics(y_fair_test,rf_predictions,\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCOLO LE METRICHE DI FAIRNESS CONSIDERANDO COME MODELLO IL DECISION TREE\n",
    "dataset = X_fair_test.copy(deep=True) # we create a copy of the test set\n",
    "dataset['is_recid'] = y_fair_test  # and join the target feature with the others\n",
    "predictions = dataset.copy(deep=True) # we do the same task\n",
    "predictions['is_recid'] = dt_predictions # but this time the target feature is made by the predictions of our model\n",
    "\n",
    "race_privileged = \"race_Caucasian\"\n",
    "race_unprivileged = [\"race_African-American\", \"race_Asian\", \"race_Other\", \"race_Native American\", \"race_Hispanic\"]\n",
    "sex_privileged = \"sex_Female\"\n",
    "sex_unprivileged = [\"sex_Male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): -0.03\n",
      "Average Odds Difference (AOD): -0.013\n",
      "Equal Opportunity Difference (EOD): -0.009\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"is_recid\",0,1,sex_privileged,sex_unprivileged)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['is_recid'] = svm_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): -0.079\n",
      "Average Odds Difference (AOD): -0.087\n",
      "Equal Opportunity Difference (EOD): -0.027\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"is_recid\",0,1,sex_privileged,sex_unprivileged)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['is_recid'] = rf_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): -0.135\n",
      "Average Odds Difference (AOD): -0.141\n",
      "Equal Opportunity Difference (EOD): -0.071\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"is_recid\",0,1,sex_privileged,sex_unprivileged)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4faiEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
