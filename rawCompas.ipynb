{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'datasets/compas-scores.csv'\n",
    "df_raw = pd.read_csv(dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11757, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['num_r_cases',\n",
    "'r_case_number',\n",
    "'r_charge_degree',\n",
    "'r_days_from_arrest',\n",
    "'r_offense_date',\n",
    "'r_charge_desc',\n",
    "'r_jail_in',\n",
    "'r_jail_out',\n",
    "'is_violent_recid',\n",
    "'num_vr_cases',\n",
    "'vr_case_number',\n",
    "'vr_charge_degree',\n",
    "'vr_offense_date',\n",
    "'vr_charge_desc',\n",
    "'v_type_of_assessment',\n",
    "'v_decile_score',\n",
    "'v_score_text',\n",
    "'v_screening_date',\n",
    "'c_arrest_date',\n",
    "'decile_score.1',\n",
    "'screening_date',\n",
    "'id',\n",
    "'compas_screening_date',\n",
    "'type_of_assessment',\n",
    "'dob',\n",
    "'name',\n",
    "'first',\n",
    "'last',\n",
    "'score_text',\n",
    "'juv_fel_count',\n",
    "'juv_misd_count',\n",
    "'juv_other_count',\n",
    "'c_jail_in',\n",
    "'c_jail_out',\n",
    "'c_offense_date',\n",
    "'c_case_number']\n",
    "\n",
    "df_raw = df_raw.drop(columns=columns_to_drop)\n",
    "df_raw = df_raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"sex\", \"age_cat\", \"race\", \"c_charge_degree\", \"c_charge_desc\"]\n",
    "df_raw = pd.get_dummies(df_raw, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply import it from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remember to use the SMOTE X and y\n",
    "X = df_raw.drop(columns=\"is_recid\")\n",
    "y = df_raw[\"is_recid\"]\n",
    "\n",
    "# Define four sets and apply the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, # 0.2 indicates a test set size of 20%\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6305581835383159\n",
      "Decision Tree Recall: 0.39662447257383965\n",
      "Decision Tree F1 Score: 0.41933085501858736\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# The fit function will do the trick\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# After the training phase, the model will be tested by predicting the values on the test set\n",
    "dt_predictions = dt_clf.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_recall = recall_score(y_test, dt_predictions)\n",
    "dt_f1_score = f1_score(y_test, dt_predictions)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "print(f\"Decision Tree Recall: {dt_recall}\")\n",
    "print(f\"Decision Tree F1 Score: {dt_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): -0.123\n",
      "Equal Opportunity Difference (EOD): -0.214\n",
      "Average Odds Difference: -0.141\n"
     ]
    }
   ],
   "source": [
    "sex_features = ['sex_Male','sex_Female'] # We want to check the fairness level regarding the protected attribute \"sex\"\n",
    "\n",
    "\n",
    "dataset = X_test.copy(deep=True) # we create a copy of the test set\n",
    "dataset['is_recid'] = y_test  # and join the target feature with the others\n",
    "\n",
    "predictions = dataset.copy(deep=True) # we do the same task\n",
    "predictions['is_recid'] = dt_predictions # but this time the target feature is made by the predictions of our model\n",
    "\n",
    "# In this way, we have two datasets. One (dataset) is the original test set containing the original values of features,\n",
    "# the other (predictions) contains the original values except for the target one, that is now made of model's predictions\n",
    "\n",
    "# These will be used by AIF to compare the classifications of the model with the original values to\n",
    "# understand if the model's answers create favouritism toward the privileged attribute\n",
    "\n",
    "\n",
    "# This is the object made of the original dataset\n",
    "aif_sex_dataset = BinaryLabelDataset( # Base class for all structured datasets with binary labels.\n",
    "        df=dataset,\n",
    "        favorable_label=1, # This means that a prediction is biased toward the privileged attribute if its value is 1 (True)\n",
    "        unfavorable_label=0,\n",
    "        label_names=['is_recid'],\n",
    "        protected_attribute_names=sex_features,\n",
    "        privileged_protected_attributes=['sex_Male'], # here we tell AIF that we want to check for predictions\n",
    "                                                      # that somehow privilege the attribute \"sex_Male\"\n",
    "    )\n",
    "\n",
    "# We do the same thing but with the predictions dataset\n",
    "aif_sex_pred = BinaryLabelDataset(\n",
    "        df=predictions,\n",
    "        favorable_label=1,\n",
    "        unfavorable_label=0,\n",
    "        label_names=['is_recid'],\n",
    "        protected_attribute_names=sex_features,\n",
    "        privileged_protected_attributes=['sex_Male'],\n",
    "    )\n",
    "\n",
    "sex_privileged_group = [{'sex_Male': 1, 'sex_Female': 0}] # The privileged group is made of males (sex_Male = True)\n",
    "sex_unprivileged_group = [{'sex_Female': 1, 'sex_Male': 0}] # The unprivileged group is made of females (sex_Female = True)\n",
    "\n",
    "# We provide the ClassificationMetric object with all the information needed:\n",
    "# aif_sex_dataset - The original test set\n",
    "# aif_sex_pred - A dataset containing the predictions of the model\n",
    "# sex_privileged_group - The privileged group\n",
    "# sex_unprivileged_group - The unprivileged group\n",
    "fairness_metrics = ClassificationMetric(dataset=aif_sex_dataset,\n",
    "                               classified_dataset=aif_sex_pred,\n",
    "                               unprivileged_groups=sex_unprivileged_group,\n",
    "                               privileged_groups=sex_privileged_group)\n",
    "\n",
    "# Values less than 0 indicate that privileged group has higher\n",
    "# proportion of predicted positive outcomes than unprivileged group.\n",
    "# Value higher than 0 indicates that unprivileged group has higher proportion\n",
    "# of predicted positive outcomes than privileged group.\n",
    "SPD = round(fairness_metrics.statistical_parity_difference(),3)\n",
    "\n",
    "# Measures the deviation from the equality of opportunity, which means that the same\n",
    "# proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
    "EOD = round(fairness_metrics.equal_opportunity_difference(),3)\n",
    "\n",
    "# Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
    "# A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
    "# groups have the same probability of being classified positively.\n",
    "AOD = round(fairness_metrics.average_odds_difference(),3)\n",
    "\n",
    "print(f\"Statistical Parity Difference (SPD): {SPD}\")\n",
    "print(f\"Equal Opportunity Difference (EOD): {EOD}\")\n",
    "print(f\"Average Odds Difference: {AOD}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
