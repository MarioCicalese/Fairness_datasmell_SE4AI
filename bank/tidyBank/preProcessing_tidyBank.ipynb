{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolocarminevalletta/Documents/SE4AI/Fairness_datasmell_SE4AI/ambiente/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} Recall: {recall}\")\n",
    "    print(f\"{model_name} F1 Score: {f1_score_value}\")\n",
    "\n",
    "def compute_classification_metric(dataset, predictions, label_name_v, favorable_label_v, unfavorable_label_v, privileged_attribute, unprivileged_attributes):\n",
    "    features = [privileged_attribute] + unprivileged_attributes\n",
    "\n",
    "    aif_age_dataset = BinaryLabelDataset(\n",
    "            df=dataset,\n",
    "            favorable_label=favorable_label_v,\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute],\n",
    "        )\n",
    "\n",
    "    aif_age_pred = BinaryLabelDataset(\n",
    "            df=predictions,\n",
    "            favorable_label=favorable_label_v,\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute],\n",
    "        )\n",
    "\n",
    "    age_privileged_group = [{privileged_attribute: 1}]\n",
    "    age_unprivileged_groups = [{attr: 1} for attr in unprivileged_attributes]\n",
    "\n",
    "    fairness_metrics = ClassificationMetric(dataset=aif_age_dataset,\n",
    "                            classified_dataset=aif_age_pred,\n",
    "                            unprivileged_groups=age_unprivileged_groups,\n",
    "                            privileged_groups=age_privileged_group)\n",
    "    \n",
    "    return fairness_metrics\n",
    "\n",
    "def compute_fairness_metrics(fairness_metrics: ClassificationMetric):\n",
    "    # Values less than 0 indicate that privileged group has higher\n",
    "    # proportion of predicted positive outcomes than unprivileged group.\n",
    "    # Value higher than 0 indicates that unprivileged group has higher proportion\n",
    "    # of predicted positive outcomes than privileged group.\n",
    "    SPD = round(fairness_metrics.statistical_parity_difference(),3)\n",
    "\n",
    "    # Measures the deviation from the equality of opportunity, which means that the same\n",
    "    # proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
    "    EOD = round(fairness_metrics.equal_opportunity_difference(),3)\n",
    "\n",
    "    # Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
    "    # A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
    "    # groups have the same probability of being classified positively.\n",
    "    AOD = round(fairness_metrics.average_odds_difference(),3)\n",
    "\n",
    "    print(f\"Statistical Parity Difference (SPD): {SPD}\")\n",
    "    print(f\"Equal Opportunity Difference (EOD): {EOD}\")\n",
    "    print(f\"Average Odds Difference: {AOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'bankTrainedTidy.csv'\n",
    "df_raw = pd.read_csv(dataset_path)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_raw.drop(columns=\"deposit\")\n",
    "y = df_raw[\"deposit\"]\n",
    "\n",
    "privileged_attributeAge = \"age_25<=age<60\"\n",
    "unprivileged_attributesAge = [\"age_age<25\", \"age_age>=60\"]\n",
    "age_features = [privileged_attributeAge] + unprivileged_attributesAge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_group = [{privileged_attributeAge: 1}]\n",
    "unprivileged_groups = [{attr: 1} for attr in unprivileged_attributesAge]\n",
    "\n",
    "dataset = X.copy(deep=True) # we recreate a copy of the whole dataset processed and balanced\n",
    "dataset['deposit'] = y # and join the target feature with the others\n",
    "\n",
    "# Create a BinaryLabelDataset using AIF360 library\n",
    "aif_dataset = BinaryLabelDataset(\n",
    "        df=dataset,\n",
    "        favorable_label=1,\n",
    "        unfavorable_label=0,\n",
    "        label_names=['deposit'],\n",
    "        protected_attribute_names=age_features,\n",
    "    )\n",
    "\n",
    "# Apply the Reweighing technique\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_group)\n",
    "dataset_transformed = RW.fit_transform(aif_dataset)\n",
    "\n",
    "# Get sample weights from the transformed dataset\n",
    "sample_weights = dataset_transformed.instance_weights\n",
    "\n",
    "# Create a fair dataset using the reweighing technique\n",
    "fair_dataset = dataset.copy(deep=True)\n",
    "fair_dataset['weights'] = sample_weights\n",
    "\n",
    "# Get features and target from the dataset\n",
    "features = dataset.columns.tolist()\n",
    "features.remove('deposit')\n",
    "target = ['deposit']\n",
    "\n",
    "# Set dataset features and target\n",
    "X_fair = fair_dataset[features]\n",
    "y_fair = fair_dataset[target]\n",
    "\n",
    "X_fair_train, X_fair_test, y_fair_train, y_fair_test, sample_weights_train, sample_weights_test = train_test_split(X_fair, y_fair, sample_weights, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(sample_weight_tr):\n",
    "    dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # The fit function will do the trick\n",
    "    dt_clf.fit(X_fair_train, y_fair_train, sample_weight=sample_weight_tr)\n",
    "\n",
    "    # After the training phase, the model will be tested by predicting the values on the test set\n",
    "    dt_predictions = dt_clf.predict(X_fair_test)\n",
    "\n",
    "    svm_classifier = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "    # Addestra il classificatore sui dati di training\n",
    "    svm_classifier.fit(X_fair_train, y_fair_train, svc__sample_weight=sample_weight_tr)\n",
    "\n",
    "    # Fai delle predizioni sui dati di test\n",
    "    svm_pred = svm_classifier.predict(X_fair_test)\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth = None, random_state=42)\n",
    "\n",
    "    rf_classifier.fit(X_fair_train, y_fair_train, sample_weight=sample_weight_tr)\n",
    "\n",
    "    rf_predictions = rf_classifier.predict(X_fair_test)\n",
    "\n",
    "    return dt_predictions,svm_pred,rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abasi\\Desktop\\Fairness_datasmell_SE4AI\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\abasi\\Desktop\\Fairness_datasmell_SE4AI\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dt_predictions, svm_pred, rf_predictions = train_models(sample_weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7941818181818182\n",
      "Decision Tree Recall: 0.7249544626593807\n",
      "Decision Tree F1 Score: 0.7377201112140871\n"
     ]
    }
   ],
   "source": [
    "compute_performance_metrics(y_fair_test,dt_predictions,\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8145454545454546\n",
      "SVM Recall: 0.697632058287796\n",
      "SVM F1 Score: 0.7502448579823702\n"
     ]
    }
   ],
   "source": [
    "compute_performance_metrics(y_fair_test,svm_pred,\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8501818181818181\n",
      "Random Forest Recall: 0.7814207650273224\n",
      "Random Forest F1 Score: 0.806390977443609\n"
     ]
    }
   ],
   "source": [
    "compute_performance_metrics(y_fair_test,rf_predictions,\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCOLO LE METRICHE DI FAIRNESS CONSIDERANDO COME MODELLO IL DECISION TREE\n",
    "dataset = X_fair_test.copy(deep=True) # we create a copy of the test set\n",
    "dataset['deposit'] = y_fair_test  # and join the target feature with the others\n",
    "predictions = dataset.copy(deep=True) # we do the same task\n",
    "predictions['deposit'] = dt_predictions # but this time the target feature is made by the predictions of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.377\n",
      "Equal Opportunity Difference (EOD): 0.126\n",
      "Average Odds Difference: 0.159\n"
     ]
    }
   ],
   "source": [
    "#Attributo privilegiato la colonna age_25<=age<60\n",
    "#Attributo non privilegiato la colonna age_age<25, age_age>=60\n",
    "# Valore favorevole 1\n",
    "# Valore non favorevole 0\n",
    "\n",
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"deposit\",1,0,privileged_attributeAge, unprivileged_attributesAge) #prima favorevole\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCOLO LE METRICHE DI FAIRNESS CONSIDERANDO COME MODELLO L'SVM\n",
    "dataset = X_fair_test.copy(deep=True)\n",
    "dataset['deposit'] = y_fair_test\n",
    "predictions = dataset.copy(deep=True) \n",
    "predictions['deposit'] = svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.23\n",
      "Equal Opportunity Difference (EOD): -0.013\n",
      "Average Odds Difference: -0.042\n"
     ]
    }
   ],
   "source": [
    "#Attributo privilegiato la colonna age_25<=age<60\n",
    "#Attributo non privilegiato la colonna age_age<25, age_age>=60\n",
    "# Valore favorevole 1\n",
    "# Valore non favorevole 0\n",
    "\n",
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"deposit\",1,0,privileged_attributeAge,unprivileged_attributesAge) #prima favorevole\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCOLO LE METRICHE DI FAIRNESS CONSIDERANDO COME MODELLO Il Random Forest\n",
    "dataset = X_fair_test.copy(deep=True)\n",
    "dataset['deposit'] = y_fair_test\n",
    "predictions = dataset.copy(deep=True) \n",
    "predictions['deposit'] = rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.512\n",
      "Equal Opportunity Difference (EOD): 0.217\n",
      "Average Odds Difference: 0.253\n"
     ]
    }
   ],
   "source": [
    "#Attributo privilegiato la colonna age_25<=age<60\n",
    "#Attributo non privilegiato la colonna age_age<25, age_age>=60\n",
    "# Valore favorevole 1\n",
    "# Valore non favorevole 0\n",
    "\n",
    "fairness_metrics = compute_classification_metric(dataset,predictions,\"deposit\",1,0,privileged_attributeAge,unprivileged_attributesAge) #prima favorevole\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
