{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolocarminevalletta/Documents/SE4AI/Fairness_datasmell_SE4AI/ambiente/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} Recall: {recall}\")\n",
    "    print(f\"{model_name} F1 Score: {f1_score_value}\")\n",
    "\n",
    "def compute_classification_metric(dataset, predictions, label_name_v, favorable_label_v, unfavorable_label_v, privileged_attribute, unprivileged_attributes):\n",
    "    features = [privileged_attribute] + unprivileged_attributes\n",
    "\n",
    "    aif_age_dataset = BinaryLabelDataset(\n",
    "            df=dataset,\n",
    "            favorable_label=favorable_label_v,\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute],\n",
    "        )\n",
    "\n",
    "    aif_age_pred = BinaryLabelDataset(\n",
    "            df=predictions,\n",
    "            favorable_label=favorable_label_v,\n",
    "            unfavorable_label=unfavorable_label_v,\n",
    "            label_names=[label_name_v],\n",
    "            protected_attribute_names=features,\n",
    "            privileged_protected_attributes=[privileged_attribute],\n",
    "        )\n",
    "\n",
    "    age_privileged_group = [{privileged_attribute: 1}]\n",
    "    age_unprivileged_groups = [{attr: 1} for attr in unprivileged_attributes]\n",
    "\n",
    "    fairness_metrics = ClassificationMetric(dataset=aif_age_dataset,\n",
    "                            classified_dataset=aif_age_pred,\n",
    "                            unprivileged_groups=age_unprivileged_groups,\n",
    "                            privileged_groups=age_privileged_group)\n",
    "    \n",
    "    return fairness_metrics\n",
    "\n",
    "def compute_fairness_metrics(fairness_metrics: ClassificationMetric):\n",
    "    # Values less than 0 indicate that privileged group has higher\n",
    "    # proportion of predicted positive outcomes than unprivileged group.\n",
    "    # Value higher than 0 indicates that unprivileged group has higher proportion\n",
    "    # of predicted positive outcomes than privileged group.\n",
    "    SPD = round(fairness_metrics.statistical_parity_difference(),3)\n",
    "\n",
    "    # Measures the deviation from the equality of opportunity, which means that the same\n",
    "    # proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
    "    EOD = round(fairness_metrics.equal_opportunity_difference(),3)\n",
    "\n",
    "    # Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
    "    # A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
    "    # groups have the same probability of being classified positively.\n",
    "    AOD = round(fairness_metrics.average_odds_difference(),3)\n",
    "\n",
    "    print(f\"Statistical Parity Difference (SPD): {SPD}\")\n",
    "    print(f\"Equal Opportunity Difference (EOD): {EOD}\")\n",
    "    print(f\"Average Odds Difference: {AOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'bankTrainedRaw.csv'\n",
    "df_raw = pd.read_csv(dataset_path)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_raw.drop(columns=\"deposit\")\n",
    "y = df_raw[\"deposit\"]\n",
    "\n",
    "# Define four sets and apply the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, # 0.2 indicates a test set size of 20%\n",
    "                                                    random_state=42)\n",
    "\n",
    "privileged_attributeAge = \"age_25<=age<60\"\n",
    "unprivileged_attributesAge = [\"age_age<25\", \"age_age>=60\"]\n",
    "age_features = [privileged_attributeAge] + unprivileged_attributesAge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Post-processed Accuracy: 0.7138378862516793\n",
      "Decision Tree Post-processed Recall: 0.8341143392689785\n",
      "Decision Tree Post-processed F1 Score: 0.7358412567176519\n"
     ]
    }
   ],
   "source": [
    "# Add your functions here\n",
    "# compute_performance_metrics and compute_classification_metric\n",
    "# Add the definition for compute_fairness_metrics\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sui dati di test\n",
    "dt_predictions = dt_clf.predict(X_test)\n",
    "\n",
    "# Calcolo delle metriche di performance per il Decision Tree grezzo\n",
    "#compute_performance_metrics(y_test, dt_predictions, \"Decision Tree\")\n",
    "\n",
    "# Aggiunta della colonna del target al dataframe di X_test e rimozione di valori mancanti\n",
    "dataset = X_test.copy(deep=True)\n",
    "dataset['deposit'] = y_test\n",
    "#dataset = dataset.dropna()\n",
    "\n",
    "# Conversione dei dati in formato BinaryLabelDataset\n",
    "test_dataset = BinaryLabelDataset(df=dataset, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Creazione di un dataset di predizioni per il post-processing\n",
    "predictions = dataset.copy(deep=True)\n",
    "predictions['deposit'] = dt_predictions\n",
    "#predictions = predictions.dropna()\n",
    "\n",
    "test_pred_dataset = BinaryLabelDataset(df=predictions, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Applicazione del post-processing con EqOddsPostprocessing\n",
    "dt_eq_odds = EqOddsPostprocessing(privileged_groups=[{age_features[0]: 1}], unprivileged_groups=[{age_features[0]: 0}])\n",
    "dt_eq_odds = dt_eq_odds.fit(test_dataset, test_pred_dataset)\n",
    "\n",
    "# Fai delle predizioni post-processate\n",
    "dt_eq_odds_pred = dt_eq_odds.predict(test_pred_dataset)\n",
    "dt_eq_odds_labels = dt_eq_odds_pred.labels\n",
    "\n",
    "# Calcolo delle metriche di performance per il modello post-processato\n",
    "compute_performance_metrics(y_test, dt_eq_odds_labels, \"Decision Tree Post-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Post-processed Accuracy: 0.7111509180474698\n",
      "Decision Tree Post-processed Recall: 0.8359887535145267\n",
      "Decision Tree Post-processed F1 Score: 0.7344586249485385\n"
     ]
    }
   ],
   "source": [
    "# Add your functions here\n",
    "# compute_performance_metrics and compute_classification_metric\n",
    "# Add the definition for compute_fairness_metrics\n",
    "\n",
    "# Train the SVM\n",
    "svm_pipeline = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "svm_classifier = svm_pipeline.named_steps['linearsvc'].fit(X_train, y_train.values.ravel())\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sui dati di test\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Aggiunta della colonna del target al dataframe di X_test e rimozione di valori mancanti\n",
    "dataset = X_test.copy(deep=True)\n",
    "dataset['deposit'] = y_test\n",
    "#dataset = dataset.dropna()\n",
    "\n",
    "# Conversione dei dati in formato BinaryLabelDataset\n",
    "test_dataset = BinaryLabelDataset(df=dataset, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Creazione di un dataset di predizioni per il post-processing\n",
    "predictions = dataset.copy(deep=True)\n",
    "predictions['deposit'] = svm_predictions\n",
    "#predictions = predictions.dropna()\n",
    "\n",
    "test_pred_dataset = BinaryLabelDataset(df=predictions, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Applicazione del post-processing con EqOddsPostprocessing\n",
    "svm_eq_odds = EqOddsPostprocessing(privileged_groups=[{age_features[0]: 1}], unprivileged_groups=[{age_features[0]: 0}])\n",
    "svm_eq_odds = svm_eq_odds.fit(test_dataset, test_pred_dataset)\n",
    "\n",
    "# Fai delle predizioni post-processate\n",
    "svm_eq_odds_pred = svm_eq_odds.predict(test_pred_dataset)\n",
    "svm_eq_odds_labels = svm_eq_odds_pred.labels\n",
    "\n",
    "# Calcolo delle metriche di performance per il modello post-processato\n",
    "compute_performance_metrics(y_test, svm_eq_odds_labels, \"Decision Tree Post-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Post-processed Accuracy: 0.7277205553067622\n",
      "Decision Tree Post-processed Recall: 0.8940955951265229\n",
      "Decision Tree Post-processed F1 Score: 0.7583465818759937\n"
     ]
    }
   ],
   "source": [
    "# Add your functions here\n",
    "# compute_performance_metrics and compute_classification_metric\n",
    "# Add the definition for compute_fairness_metrics\n",
    "\n",
    "# Train the Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth = None, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predizione sui dati di test\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Aggiunta della colonna del target al dataframe di X_test e rimozione di valori mancanti\n",
    "dataset = X_test.copy(deep=True)\n",
    "dataset['deposit'] = y_test\n",
    "#dataset = dataset.dropna()\n",
    "\n",
    "# Conversione dei dati in formato BinaryLabelDataset\n",
    "test_dataset = BinaryLabelDataset(df=dataset, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Creazione di un dataset di predizioni per il post-processing\n",
    "predictions = dataset.copy(deep=True)\n",
    "predictions['deposit'] = rf_predictions\n",
    "#predictions = predictions.dropna()\n",
    "\n",
    "test_pred_dataset = BinaryLabelDataset(df=predictions, label_names=['deposit'], protected_attribute_names=age_features)\n",
    "\n",
    "# Applicazione del post-processing con EqOddsPostprocessing\n",
    "rf_eq_odds = EqOddsPostprocessing(privileged_groups=[{age_features[0]: 1}], unprivileged_groups=[{age_features[0]: 0}])\n",
    "rf_eq_odds = rf_eq_odds.fit(test_dataset, test_pred_dataset)\n",
    "\n",
    "# Fai delle predizioni post-processate\n",
    "rf_eq_odds_pred = rf_eq_odds.predict(test_pred_dataset)\n",
    "rf_eq_odds_labels = rf_eq_odds_pred.labels\n",
    "\n",
    "# Calcolo delle metriche di performance per il modello post-processato\n",
    "compute_performance_metrics(y_test, rf_eq_odds_labels, \"Decision Tree Post-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataset di test con le etichette originali e predizioni del modello\n",
    "test_dataset_with_labels = X_test.copy(deep=True)\n",
    "test_dataset_with_labels['deposit'] = y_test\n",
    "\n",
    "# Creazione del dataset di predizioni del modello post-processato\n",
    "predictions_post_processed = X_test.copy(deep=True)\n",
    "predictions_post_processed['deposit'] = dt_eq_odds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.164\n",
      "Equal Opportunity Difference (EOD): -0.012\n",
      "Average Odds Difference: -0.001\n"
     ]
    }
   ],
   "source": [
    "# Calcolo delle metriche di fairness\n",
    "fairness_metrics = compute_classification_metric(test_dataset_with_labels,predictions_post_processed,'deposit',1,0,privileged_attributeAge,unprivileged_attributesAge)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataset di test con le etichette originali e predizioni del modello\n",
    "test_dataset_with_labels = X_test.copy(deep=True)\n",
    "test_dataset_with_labels['deposit'] = y_test\n",
    "\n",
    "# Creazione del dataset di predizioni del modello post-processato\n",
    "predictions_post_processed = X_test.copy(deep=True)\n",
    "predictions_post_processed['deposit'] = svm_eq_odds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.169\n",
      "Equal Opportunity Difference (EOD): -0.001\n",
      "Average Odds Difference: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Calcolo delle metriche di fairness\n",
    "fairness_metrics = compute_classification_metric(test_dataset_with_labels,predictions_post_processed,'deposit',1,0,privileged_attributeAge,unprivileged_attributesAge)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataset di test con le etichette originali e predizioni del modello\n",
    "test_dataset_with_labels = X_test.copy(deep=True)\n",
    "test_dataset_with_labels['deposit'] = y_test\n",
    "\n",
    "# Creazione del dataset di predizioni del modello post-processato\n",
    "predictions_post_processed = X_test.copy(deep=True)\n",
    "predictions_post_processed['deposit'] = rf_eq_odds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.187\n",
      "Equal Opportunity Difference (EOD): 0.015\n",
      "Average Odds Difference: -0.016\n"
     ]
    }
   ],
   "source": [
    "# Calcolo delle metriche di fairness\n",
    "fairness_metrics = compute_classification_metric(test_dataset_with_labels,predictions_post_processed,'deposit',1,0,privileged_attributeAge,unprivileged_attributesAge)\n",
    "compute_fairness_metrics(fairness_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
